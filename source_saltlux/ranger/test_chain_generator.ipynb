{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de997662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _init import *\n",
    "\n",
    "import os, torch, random\n",
    "from typing import List\n",
    "\n",
    "from ranger.utils import json_utils\n",
    "from ranger.vllm.vllm_engine import VllmEngine\n",
    "from ranger.corag.corag_agent import CoRagAgent\n",
    "from ranger.corag.corag_result import ChainResult, QueryResult\n",
    "\n",
    "# import logging\n",
    "# logging.getLogger(\"vllm\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ecf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. CUDA 알고리즘의 결정성 강제 (가장 중요)\n",
    "# os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8' \n",
    "\n",
    "# # 2. PyTorch 결정성 설정\n",
    "# torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5230de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    print(f'set_seed() seed : {seed}')\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babed54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "cg_device = 0\n",
    "dtype = 'float16'\n",
    "max_model_len = 4096\n",
    "max_token_gen = 128\n",
    "\n",
    "vllm_config = {\n",
    "    \"model_name\": model_name,\n",
    "    'device': f'cuda:{cg_device}',\n",
    "    'gpu_memory_utilization': 0.30,\n",
    "    'dtype': dtype,\n",
    "    'max_model_len': max_model_len,\n",
    "    'max_token_gen': max_token_gen,\n",
    "    'top_k_query': 20,                          # main query 검색 문서 수\n",
    "    'top_k_sub_query': 5,                       # sub query  검색 문서 수\n",
    "    'temperature': 0.7,                         # 체인이 다양하게 생성되어야 하기 때문에, 높은 값 할당\n",
    "    'n_logprob': 20,                            # 정답에 대한 모델의 confidence 계산 시에 확인하려는 상위 N개의 토큰 수 (최대 20까지만 가능)\n",
    "    \"task_desc\": \"answer multi-hop questions\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ba31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_engine = VllmEngine(\n",
    "    model_name=vllm_config['model_name'],\n",
    "    device=vllm_config['device'],\n",
    "    gpu_memory_utilization=vllm_config['gpu_memory_utilization'],\n",
    "    dtype=vllm_config['dtype'],\n",
    "    max_model_len=vllm_config['max_model_len'],\n",
    "    n_logprob=vllm_config['n_logprob']\n",
    ")\n",
    "\n",
    "vllm_engine._seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corag_agent = CoRagAgent(\n",
    "    vllm_engine,\n",
    "    vllm_config['max_model_len'],\n",
    "    vllm_config['max_token_gen'],\n",
    "    vllm_config['temperature'],\n",
    "    vllm_config['top_k_query'],\n",
    "    vllm_config['top_k_sub_query']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datas_shuffle(datas: list, seed: int):\n",
    "    rng = random.Random(seed)\n",
    "    rng.shuffle(datas)\n",
    "\n",
    "\n",
    "def load_datas(train_data_path: str, test_data_path: str, seed: int, do_print=False):\n",
    "    train_datas = json_utils.load_file(train_data_path)\n",
    "    test_datas = json_utils.load_file(test_data_path)\n",
    "    datas_shuffle(train_datas, seed)\n",
    "    datas_shuffle(test_datas, seed)\n",
    "\n",
    "    if do_print:\n",
    "        print(f'\\n# ranger_runner.load_datas() train_datas[0] : {json_utils.to_str(train_datas[0])}')\n",
    "        print(f'# ranger_runner.load_datas() test_datas[0] : {json_utils.to_str(test_datas[0])}\\n')\n",
    "    \n",
    "    return train_datas, test_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a71453",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = f'/home/nlpshlee/dev_env/git/repos/ranger'\n",
    "data_dir = f'{work_dir}/data'\n",
    "out_dir = f'{work_dir}/output'\n",
    "\n",
    "train_data_path = f'{data_dir}/custom_musique_train_5000_final.jsonl'\n",
    "test_data_path = f'{data_dir}/custom_multihopqa_eval_1000.jsonl'\n",
    "train_datas, test_datas = load_datas(train_data_path, test_data_path, seed, do_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generate_batch(datas, n_chains, chain_depth, adapter_path=''):\n",
    "    query_results: List[QueryResult] = corag_agent.generate_batch(\n",
    "        task_desc=vllm_config['task_desc'],\n",
    "        datas=datas,\n",
    "        n_chains=n_chains,\n",
    "        chain_depth=chain_depth,\n",
    "        adapter_path=adapter_path\n",
    "    )\n",
    "\n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebfbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_query_results(query_results: List[QueryResult]):\n",
    "    print(f'query_results size : {len(query_results)}\\n')\n",
    "\n",
    "    for query_result in query_results:\n",
    "        print(f'query_id : {query_result._query_id}')\n",
    "        print(f'query : {query_result._query}')\n",
    "        print(f'answers (len:{len(query_result._answers)}) : {query_result._answers}')\n",
    "        print(f'doc_ids (len:{len(query_result._doc_ids)}) : {query_result._doc_ids}')\n",
    "        print(f'documents :')\n",
    "        for i, document in enumerate(query_result._documents):\n",
    "            document = document.replace('\\n', ' ')\n",
    "            print(f'[{i+1}] : {document}')\n",
    "\n",
    "        chain_results: List[ChainResult] = query_result._chain_results\n",
    "        print(f'\\n\\tchain_results size : {len(chain_results)}\\n')\n",
    "\n",
    "        for chain_idx, chain_result in enumerate(chain_results):\n",
    "            print(f'\\tchain_idx : {chain_idx+1}')\n",
    "            print(f'\\tsub_querys (len:{len(chain_result._sub_querys)}) : {chain_result._sub_querys}')\n",
    "            print(f'\\tsub_answers (len:{len(chain_result._sub_answers)}) : {chain_result._sub_answers}')\n",
    "            print(f'\\tdoc_ids_list : {chain_result._doc_ids_list}')\n",
    "            \n",
    "            print(f'\\tdocuments_list :\\n\\t[depth][document_idx]')\n",
    "            for i, documents in enumerate(chain_result._documents_list):\n",
    "                for j, document in enumerate(documents):\n",
    "                    document = document.replace('\\n', ' ')\n",
    "                    print(f'\\t[{i+1}][{j+1}] : {document}')\n",
    "            print(f'\\tfinal_answers (len:{len(chain_result._final_answers)}) : {chain_result._final_answers}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains, chain_depth = 5, 5\n",
    "\n",
    "query_results = test_generate_batch(train_datas[:10], n_chains, chain_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d50764",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_path = '/home/nlpshlee/dev_env/git/repos/ranger/output/test/lora_adapter_2025-12-03-07-13-16/'\n",
    "\n",
    "query_results_adapter = test_generate_batch(train_datas[:10], n_chains, chain_depth, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 결과를 파일로 저장해서, diff 비교\n",
    "# print_query_results(query_results_adapter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
