{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _init import *\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from ranger.utils import json_utils\n",
    "from ranger.reward.reward_calculator import RewardCalculator\n",
    "from ranger.train.ranger_trainer import RangerTrainer\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36574263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    print(f'set_seed() seed : {seed}\\n')\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33517a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = f'/home/nlpshlee/dev_env/git/repos/ranger'\n",
    "data_dir = f'{work_dir}/data'\n",
    "out_dir = f'{work_dir}/outputs/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a66fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(model: AutoModelForCausalLM, tokenizer: AutoTokenizer, text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=20, \n",
    "            do_sample=False,  # [중요] 랜덤성 제거 (Greedy Decoding)\n",
    "            temperature=None,\n",
    "            top_p=None\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe38740",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_calculator = RewardCalculator(REWARD_CONFIG['reward_option'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 재시작하고 여기까지만 실행시켜 봤을 때, 동일한지 확인\n",
    "# MODEL_CONFIG['resume_run_time'] = '2025-12-18-03-35-16'\n",
    "\n",
    "# ranger_trainer3 = RangerTrainer(\n",
    "#     MODEL_CONFIG,\n",
    "#     reward_calculator,\n",
    "#     out_dir\n",
    "# )\n",
    "\n",
    "# gen4 = get_response(ranger_trainer3._model, ranger_trainer3._tokenizer, \"Hello, tell me a story.\")\n",
    "# print(f'[Resume reboot] gen4 : {gen4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranger_trainer = RangerTrainer(\n",
    "    MODEL_CONFIG,\n",
    "    reward_calculator,\n",
    "    out_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 변경 전 모델로 생성\n",
    "gen1 = get_response(ranger_trainer._model, ranger_trainer._tokenizer, \"Hello, tell me a story.\")\n",
    "print(f'[Org] gen1 : {gen1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3888b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 가중치 강제 변경\n",
    "# 학습을 안 했어도 값이 변했다는 것을 증명하기 위해 강제로 값을 더함\n",
    "with torch.no_grad():\n",
    "    modified_count = 0\n",
    "\n",
    "    for name, param in ranger_trainer._model.named_parameters():\n",
    "        if \"lora_\" in name:\n",
    "            noise = torch.randn_like(param) \n",
    "            param.copy_(noise)\n",
    "            modified_count += 1\n",
    "\n",
    "    print(f\"{modified_count}개의 LoRA 파라미터를 망가뜨렸습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 변경된 모델로 생성\n",
    "gen2 = get_response(ranger_trainer._model, ranger_trainer._tokenizer, \"Hello, tell me a story.\")\n",
    "print(f'[Mod] gen2 : {gen2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f24d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 모델 저장\n",
    "ranger_trainer._save('1', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291fd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 메모리 해제 (확실한 테스트를 위해)\n",
    "del ranger_trainer._model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92004b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 저장된 경로를 바탕으로 새로운 모델 초기화\n",
    "MODEL_CONFIG['resume_run_time'] = ranger_trainer._run_time\n",
    "\n",
    "ranger_trainer2 = RangerTrainer(\n",
    "    MODEL_CONFIG,\n",
    "    reward_calculator,\n",
    "    out_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 저장된 모델로 생성\n",
    "gen3 = get_response(ranger_trainer2._model, ranger_trainer2._tokenizer, \"Hello, tell me a story.\")\n",
    "print(f'[Resume] gen3 : {gen3}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
