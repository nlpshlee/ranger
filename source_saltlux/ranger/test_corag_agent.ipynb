{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd0687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _init import *\n",
    "\n",
    "import os, torch, random\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from ranger.utils import json_utils\n",
    "from ranger.vllm.vllm_engine import VllmEngine\n",
    "from ranger.corag.corag_agent import CoragAgent\n",
    "from ranger.corag.corag_result import ChainResult, QueryResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5230de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    print(f'set_seed() seed : {seed}')\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babed54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "device = 0\n",
    "dtype = 'float16'\n",
    "max_seq_length = 4096\n",
    "max_new_tokens = 128\n",
    "temperature = 0.0\n",
    "gpu_memory_utilization = 0.3\n",
    "\n",
    "vllm_config = {\n",
    "    \"model_name\": model_name,\n",
    "    'device': f'cuda:{device}',\n",
    "    'dtype': dtype,\n",
    "    'max_seq_length': max_seq_length,\n",
    "    'max_new_tokens': max_new_tokens,\n",
    "    'temperature': temperature,\n",
    "    'gpu_memory_utilization': gpu_memory_utilization,\n",
    "    'n_log_prob': 20\n",
    "}\n",
    "\n",
    "corag_config = {\n",
    "    'top_k_query': 20,\n",
    "    'top_k_sub_query': 5,\n",
    "    \"task_desc\": \"answer multi-hop questions\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f47bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_engine = VllmEngine(\n",
    "    model_name=vllm_config['model_name'],\n",
    "    device=vllm_config['device'],\n",
    "    dtype=vllm_config['dtype'],\n",
    "    max_seq_length=vllm_config['max_seq_length'],\n",
    "    max_new_tokens=vllm_config['max_new_tokens'],\n",
    "    temperature=vllm_config['temperature'],\n",
    "    gpu_memory_utilization=vllm_config['gpu_memory_utilization'],\n",
    "    n_log_prob=vllm_config['n_log_prob']\n",
    ")\n",
    "\n",
    "vllm_engine._seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385862df",
   "metadata": {},
   "outputs": [],
   "source": [
    "corag_agent = CoragAgent(\n",
    "    engine=vllm_engine,\n",
    "    top_k_query=corag_config['top_k_query'],\n",
    "    top_k_sub_query=corag_config['top_k_sub_query'],\n",
    "    task_desc=corag_config['task_desc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datas_shuffle(datas: list, seed: int):\n",
    "    rng = random.Random(seed)\n",
    "    rng.shuffle(datas)\n",
    "\n",
    "\n",
    "def load_datas(train_data_path: str, test_data_path: str, seed: int, do_print=False):\n",
    "    train_datas = json_utils.load_file(train_data_path)\n",
    "    test_datas = json_utils.load_file(test_data_path)\n",
    "    datas_shuffle(train_datas, seed)\n",
    "    datas_shuffle(test_datas, seed)\n",
    "    \n",
    "    return train_datas, test_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a71453",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = f'/home/nlpshlee/dev_env/git/repos/ranger'\n",
    "data_dir = f'{work_dir}/data'\n",
    "out_dir = f'{work_dir}/output'\n",
    "\n",
    "train_data_path = f'{data_dir}/custom_musique_train_5000_final.jsonl'\n",
    "test_data_path = f'{data_dir}/custom_multihopqa_eval_1000.jsonl'\n",
    "train_datas, test_datas = load_datas(train_data_path, test_data_path, seed, do_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generate_batch(datas, n_chains, chain_depth, adapter_path=''):\n",
    "    query_results: List[QueryResult] = corag_agent.generate_batch(\n",
    "        datas=datas,\n",
    "        n_chains=n_chains,\n",
    "        chain_depth=chain_depth,\n",
    "        adapter_path=adapter_path\n",
    "    )\n",
    "\n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebfbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_query_results(query_results: List[QueryResult]):\n",
    "    print(f'query_results size : {len(query_results)}\\n')\n",
    "\n",
    "    for query_result in query_results:\n",
    "        print(f'query_id : {query_result._query_id}')\n",
    "        print(f'query : {query_result._query}')\n",
    "        print(f'answers (len:{len(query_result._answers)}) : {query_result._answers}')\n",
    "        print(f'doc_ids (len:{len(query_result._doc_ids)}) : {query_result._doc_ids}')\n",
    "        print(f'docs :')\n",
    "        for i, doc in enumerate(query_result._docs):\n",
    "            doc = doc.replace('\\n', ' ')\n",
    "            print(f'[{i+1}] : {doc}')\n",
    "\n",
    "        chain_results: List[ChainResult] = query_result._chain_results\n",
    "        print(f'\\n\\tchain_results size : {len(chain_results)}\\n')\n",
    "\n",
    "        for chain_idx, chain_result in enumerate(chain_results):\n",
    "            print(f'\\tchain_idx : {chain_idx+1}')\n",
    "            print(f'\\tsub_querys (len:{len(chain_result._sub_querys)}) : {chain_result._sub_querys}')\n",
    "            print(f'\\tsub_answers (len:{len(chain_result._sub_answers)}) : {chain_result._sub_answers}')\n",
    "            print(f'\\tdoc_ids_list : {chain_result._doc_ids_list}')\n",
    "            \n",
    "            print(f'\\tdocs_list :\\n\\t[depth][doc_idx]')\n",
    "            for i, docs in enumerate(chain_result._docs_list):\n",
    "                for j, doc in enumerate(docs):\n",
    "                    doc = doc.replace('\\n', ' ')\n",
    "                    print(f'\\t[{i+1}][{j+1}] : {doc}')\n",
    "            print(f'\\tfinal_answers (len:{len(chain_result._final_answers)}) : {chain_result._final_answers}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains, chain_depth = 5, 5\n",
    "\n",
    "query_results = test_generate_batch(train_datas[:10], n_chains, chain_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_path = '/home/nlpshlee/dev_env/git/repos/ranger/outputs/test/lora_adapter_2025-12-03-07-13-16/'\n",
    "\n",
    "query_results_adapter = test_generate_batch(train_datas[:10], n_chains, chain_depth, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 결과를 파일로 저장해서, diff 비교\n",
    "print_query_results(query_results_adapter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
